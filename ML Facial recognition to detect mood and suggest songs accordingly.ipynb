{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee162d3",
   "metadata": {},
   "source": [
    "# LGMVIP Task 10- ML Facial recognition to detect mood and suggest songs accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc464c",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d235cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from skimage.io import imread\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D,MaxPooling2D,Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version :\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e4592",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "row, col = 48, 48\n",
    "classes = 7\n",
    "\n",
    "def count_exp(path, set_):\n",
    "    dict_ = {}\n",
    "    for expression in os.listdir(path):\n",
    "        dir_ = path +\"/\" +expression\n",
    "        dict_[expression] = len(os.listdir(dir_))\n",
    "    df = pd.DataFrame(dict_, index=[set_])\n",
    "    return df\n",
    "train_count = count_exp(train_dir, 'train')\n",
    "test_count = count_exp(test_dir, 'test')\n",
    "print(train_count)\n",
    "print(test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7bc8e",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213848c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "train_dir = \"train\\\\\"\n",
    "test_dir = \"test\\\\\"\n",
    "total_labels = len(os.listdir(train_dir))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=5, ncols=total_labels, figsize=(35, 25))\n",
    "for x in range(5):\n",
    "    for y,v in zip(range(total_labels),os.listdir(train_dir)):\n",
    "        ax[x][y].imshow(imread(train_dir+v+'/'+os.listdir(train_dir+v)[x]), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92351eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "for i in os.listdir(train_dir):\n",
    "    directory = train_dir + i\n",
    "    df[i] = len(os.listdir(directory))\n",
    "df = pd.DataFrame(df, index=[\"total\"]).transpose().sort_values(\"total\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.barplot(x=df.index, y=\"total\", palette=\"mako\", data=df)\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Total images of each label in train dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "happy = os.listdir(train_dir+'happy/')\n",
    "dim1, dim2 = [], []\n",
    "\n",
    "for img_filename in happy:\n",
    "    img = imread(train_dir+'happy/'+img_filename)\n",
    "    d1, d2 = img.shape\n",
    "    dim1.append(d1)\n",
    "    dim2.append(d2)\n",
    "\n",
    "img_shape = (int(np.mean(dim1)), int(np.mean(dim2)), 1)\n",
    "sns.jointplot(x=dim1, y=dim2,color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42659732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1/255,\n",
    "                                rotation_range=40,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest')\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "img_shape = (int(np.mean(dim1)), int(np.mean(dim2)), 1)\n",
    "\n",
    "train_generator = train_gen.flow_from_directory(directory=train_dir,\n",
    "                                                target_size=(img_shape[0], img_shape[1]),\n",
    "                                                color_mode='grayscale',\n",
    "                                                batch_size=64,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)\n",
    "\n",
    "test_generator = test_gen.flow_from_directory(directory=test_dir,\n",
    "                                                target_size=(img_shape[0], img_shape[1]),\n",
    "                                                color_mode='grayscale',\n",
    "                                                batch_size=64,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc67a3",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a5e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', input_shape=img_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=len(os.listdir(train_dir)), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a1990",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c11d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "validation_steps = test_generator.n // test_generator.batch_size\n",
    "num_epochs = 20\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1,\n",
    "                    #callbacks=callbacks,\n",
    "                    validation_data=test_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7effecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed73aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"validation accuracy :\", str(test_acc*100)+\"%\")\n",
    "print(\"validation loss :\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a984641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))\n",
    "ax[0].plot(epochs, acc, 'g', label='Training accuracy')\n",
    "ax[0].plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "ax[0].legend(loc=0)\n",
    "ax[1].plot(epochs, loss, 'g', label='Training loss')\n",
    "ax[1].plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "ax[1].legend(loc=0)\n",
    "\n",
    "plt.suptitle('Training and validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ecd337",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff24e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = np.argmax(model.predict(test_generator), axis=-1)\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=test_generator.class_indices.keys()), end='\\n\\n\\n')\n",
    "\n",
    "cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.heatmap(cm, cmap=plt.cm.viridis, annot=True, fmt='.0f', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0006835",
   "metadata": {},
   "source": [
    "### Testing our model with new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"E:\\\\GrowMore\\\\Surprise.jpg\")\n",
    "from IPython.display import Image\n",
    "Image(filename='E:\\\\GrowMore\\\\Surprise.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fb072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.python.keras.models import load_model\n",
    "import os\n",
    "\n",
    "\n",
    "# # load the trained model\n",
    "\n",
    "model = tf.keras.models.load_model(\"model.h5\",\n",
    "    custom_objects={'Functional':tf.keras.models.Model})\n",
    "# A list of emoticon categories\n",
    "EMOTIONS = ['Angry', 'Disgust', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "# Load image\n",
    "img = image\n",
    "\n",
    "# Trim the image to 48 x 48, and turn the grayscale image, normalization\n",
    "frame = cv2.resize(img,(48,48),interpolation=cv2.INTER_BITS2)\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) / 255.0\n",
    "\n",
    "# Reinvent the image dimension\n",
    "gray = gray.reshape(1,48,48,1)\n",
    "\n",
    "# Output the prediction\n",
    "predicts = model.predict(gray)[0]\n",
    "label = EMOTIONS[predicts.argmax()]\n",
    "for (i,j) in zip(range(7),EMOTIONS):\n",
    "    predictss = predicts[i]\n",
    "    print(\"{:^10s}\".format(j)+\"prediction rate is   {0:.2f}%\".format(predictss))\n",
    "print( \"\\n\\n The system considers this expression to be:\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (label=='Angry'):\n",
    "    path=\"E:\\\\GrowMore\\\\Angry\"\n",
    "    files=os.listdir(path)\n",
    "    d=random.choice(files)\n",
    "    print(\"Now Playing:\",d)\n",
    "    audio = Audio(filename='E:\\\\GrowMore\\\\Angry\\\\'+ d,autoplay=True)\n",
    "    display(audio)\n",
    "    \n",
    "elif (label=='Disgust'):\n",
    "    path=\"E:\\\\GrowMore\\\\Disgust\\\\\"\n",
    "    files=os.listdir(path)\n",
    "    d=random.choice(files)\n",
    "    print(\"Now Playing:\",d)\n",
    "    audio = Audio(filename='E:\\\\GrowMore\\\\Disgust\\\\'+ d,autoplay=True)\n",
    "    display(audio)\n",
    "    \n",
    "elif (label==\"Happy\"):\n",
    "    path=\"E:\\\\GrowMore\\\\Happy\\\\\"\n",
    "    files=os.listdir(path)\n",
    "    d=random.choice(files)m\n",
    "    print(\"Now Playing:\",d)\n",
    "    audio = Audio(filename='E:\\\\GrowMore\\\\Happy\\\\'+ d,autoplay=True)\n",
    "    display(audio)\n",
    "    \n",
    "elif (label=='Sad'):\n",
    "    path=\"E:\\\\GrowMore\\\\Sad\\\\\"\n",
    "    files=os.listdir(path)\n",
    "    d=random.choice(files)\n",
    "    print(\"Now Playing:\",d)\n",
    "    audio = Audio(filename='E:\\\\GrowMore\\\\Sad\\\\'+ d,autoplay=True)\n",
    "    display(audio)\n",
    "    \n",
    "elif (label=='Surprise'):\n",
    "    path=\"E:\\\\GrowMore\\\\Surprise\\\\\"\n",
    "    files=os.listdir(path)\n",
    "    d=random.choice(files)\n",
    "    print(\"Now Playing:\",d)\n",
    "    audio = Audio(filename='E:\\\\GrowMore\\\\Surprise\\\\'+ d,autoplay=True)\n",
    "    display(audio)\n",
    "    \n",
    "elif (label=='Neutral'):\n",
    "    path=\"E:\\\\GrowMore\\\\Neutral\\\\\"\n",
    "    files=os.listdir(path)\n",
    "    d=random.choice(files)\n",
    "    print(\"Now Playing:\",d)\n",
    "    audio = Audio(filename='E:\\\\GrowMore\\\\Neutral\\\\'+ d,autoplay=True)\n",
    "    display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d045ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
